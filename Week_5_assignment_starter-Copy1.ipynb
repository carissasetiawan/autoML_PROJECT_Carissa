{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use TPOT to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "    - REMEMBER: TPOT only finds the optimized processing pipeline and model. It doesn't create the model. \n",
    "        - You can use `tpot.export('my_model_name.py')` (assuming you called your TPOT object tpot) and it will save a Python template with an example of the optimized pipeline. \n",
    "        - Use the template code saved from the `export()` function in your program.\n",
    "- create a Python script/file/module using code from the exported template above that\n",
    "    - create a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5558b",
   "metadata": {},
   "source": [
    "# Use TPOTT\n",
    "\tâ–ª\tChoose a metric you think is best to use for finding the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86830ae8",
   "metadata": {},
   "source": [
    "In these next steps we will install TPOT and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28358a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d8d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4e1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99afcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3606ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TPOT in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (0.11.7)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.7.3)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.1.2)\n",
      "Requirement already satisfied: update-checker>=0.16 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.21.5)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.5.1)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (4.64.0)\n",
      "Requirement already satisfied: deap>=1.2 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.3.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from TPOT) (1.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->TPOT) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->TPOT) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->TPOT) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.0->TPOT) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from update-checker>=0.16->TPOT) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3f16a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: XGBoost in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from XGBoost) (1.21.5)\n",
      "Requirement already satisfied: scipy in /Users/carissa/opt/anaconda3/lib/python3.9/site-packages (from XGBoost) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d59d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e37ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b0f43",
   "metadata": {},
   "source": [
    "Now I'm going to load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e44348bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Totalcharges_tenure_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7590-VHVEG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>29.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575-GNVDE</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>55.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668-QPYBK</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>54.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795-CFOCW</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>40.905556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237-HQITU</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>75.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840-RESVB</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0</td>\n",
       "      <td>82.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234-XADUH</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>0</td>\n",
       "      <td>102.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801-JZAZL</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>0</td>\n",
       "      <td>31.495455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361-LTMKD</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>1</td>\n",
       "      <td>76.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186-AJIEK</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0</td>\n",
       "      <td>103.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "7590-VHVEG       1             0         0              0           29.85   \n",
       "5575-GNVDE      34             1         1              1           56.95   \n",
       "3668-QPYBK       2             1         0              1           53.85   \n",
       "7795-CFOCW      45             0         1              2           42.30   \n",
       "9237-HQITU       2             1         0              0           70.70   \n",
       "...            ...           ...       ...            ...             ...   \n",
       "6840-RESVB      24             1         1              1           84.80   \n",
       "2234-XADUH      72             1         1              3          103.20   \n",
       "4801-JZAZL      11             0         0              0           29.60   \n",
       "8361-LTMKD       4             1         0              1           74.40   \n",
       "3186-AJIEK      66             1         2              2          105.65   \n",
       "\n",
       "            TotalCharges  Churn  Totalcharges_tenure_ratio  \n",
       "customerID                                                  \n",
       "7590-VHVEG         29.85      0                  29.850000  \n",
       "5575-GNVDE       1889.50      0                  55.573529  \n",
       "3668-QPYBK        108.15      1                  54.075000  \n",
       "7795-CFOCW       1840.75      0                  40.905556  \n",
       "9237-HQITU        151.65      1                  75.825000  \n",
       "...                  ...    ...                        ...  \n",
       "6840-RESVB       1990.50      0                  82.937500  \n",
       "2234-XADUH       7362.90      0                 102.262500  \n",
       "4801-JZAZL        346.45      0                  31.495455  \n",
       "8361-LTMKD        306.60      1                  76.650000  \n",
       "3186-AJIEK       6844.50      0                 103.704545  \n",
       "\n",
       "[7032 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('prepped_telecom_data.csv', index_col='customerID')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e8b18",
   "metadata": {},
   "source": [
    "Next I will split it into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9d861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Churn', axis=1)\n",
    "targets = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cff2d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc57804",
   "metadata": {},
   "source": [
    "Now we are using TPOTClassifer to find the accuracy score fo the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98c93dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/600 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8026666666666668\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8026666666666668\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8030222222222223\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8037333333333333\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8037333333333333\n",
      "\n",
      "Best pipeline: RandomForestClassifier(OneHotEncoder(MLPClassifier(input_matrix, alpha=0.001, learning_rate_init=0.1), minimum_fraction=0.25, sparse=False, threshold=10), bootstrap=False, criterion=entropy, max_features=0.05, min_samples_leaf=16, min_samples_split=19, n_estimators=100)\n",
      "0.7796730632551528\n",
      "CPU times: user 57.8 s, sys: 1.13 s, total: 58.9 s\n",
      "Wall time: 9min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTClassifier(generations=5, population_size=100, verbosity=2, n_jobs=-1, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc430873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8051555555555556\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8051555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carissa/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 3 - Current best internal CV score: 0.8051555555555556\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8051555555555556\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8055111111111112\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.2, min_samples_leaf=12, min_samples_split=17, n_estimators=100)\n",
      "0.7768301350390903\n",
      "CPU times: user 26.4 s, sys: 655 ms, total: 27 s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, n_jobs=-1, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febe274",
   "metadata": {},
   "source": [
    "Next, we are using TPOT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61cf704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "841fcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e97a982d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.3008936146508659\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.3008936146508659\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.3008936146508659\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.3008936146508659\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.30240683732295803\n",
      "\n",
      "Best pipeline: RandomForestRegressor(LassoLarsCV(input_matrix, normalize=True), bootstrap=True, max_features=0.15000000000000002, min_samples_leaf=8, min_samples_split=3, n_estimators=100)\n",
      "0.25619644386439755\n",
      "CPU times: user 27.5 s, sys: 513 ms, total: 28 s\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2, n_jobs=-1, scoring='r2', random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93dae46",
   "metadata": {},
   "source": [
    "Based on the scores, it looks like TPOT classifier came up with a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8419f3c",
   "metadata": {},
   "source": [
    "Next I'm exporting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "919c6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('TPOTClassifierModel.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b638471",
   "metadata": {},
   "source": [
    "# Create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "\tâ–ª\tcreate a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "\tâ–ª\tyour Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "\tâ–ª\tthe true values for the new data are [1, 0, 0, 1, 0] if you're interested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90c2890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "# tpot_data = pd.read_csv('prepped_telecom_data.csv', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "# features = tpot_data.drop('target', axis=1)\n",
    "# training_features, testing_features, training_target, testing_target = \\\n",
    "#            train_test_split(features, tpot_data['target'], random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: 0.8037333333333333\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=MLPClassifier(alpha=0.001, learning_rate_init=0.1)),\n",
    "    OneHotEncoder(minimum_fraction=0.25, sparse=False, threshold=10),\n",
    "    RandomForestClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.05, min_samples_leaf=16, min_samples_split=19, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65841102",
   "metadata": {},
   "source": [
    "# Test your Python module and function with the new data, new_churn_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736907b",
   "metadata": {},
   "source": [
    "In this step I'm setting the data and testing the module to see what it predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5dd4804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>charge_per_tenure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9305-CKSKC</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>97.40</td>\n",
       "      <td>811.70</td>\n",
       "      <td>36.895455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452-KNGVK</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.30</td>\n",
       "      <td>1701.95</td>\n",
       "      <td>212.743750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723-OKKJM</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.25</td>\n",
       "      <td>250.90</td>\n",
       "      <td>8.960714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7832-POPKP</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>101.70</td>\n",
       "      <td>3106.56</td>\n",
       "      <td>50.105806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6348-TACGU</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.15</td>\n",
       "      <td>3440.97</td>\n",
       "      <td>344.097000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "9305-CKSKC      22             1         0              2           97.40   \n",
       "1452-KNGVK       8             0         1              1           77.30   \n",
       "6723-OKKJM      28             1         0              0           28.25   \n",
       "7832-POPKP      62             1         0              2          101.70   \n",
       "6348-TACGU      10             0         0              1           51.15   \n",
       "\n",
       "            TotalCharges  charge_per_tenure  \n",
       "customerID                                   \n",
       "9305-CKSKC        811.70          36.895455  \n",
       "1452-KNGVK       1701.95         212.743750  \n",
       "6723-OKKJM        250.90           8.960714  \n",
       "7832-POPKP       3106.56          50.105806  \n",
       "6348-TACGU       3440.97         344.097000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_churn_data.csv', index_col='customerID')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13efe3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "r = exported_pipeline.predict(df)\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b800c",
   "metadata": {},
   "source": [
    "The model successfully returned the churn prediction for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "In this weekâ€™s assignment, I first setup the TPOT model then based on the testing, I found out that TPOT classifier is the best model based on the accuracy score.\n",
    "\n",
    "Then I created a Python module that returns the probability of churn for each row in the data frame. Next, I tested whether the model will work and I got some probabilities for each row of the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112e621",
   "metadata": {},
   "source": [
    "# Upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a1763c",
   "metadata": {},
   "source": [
    "???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
